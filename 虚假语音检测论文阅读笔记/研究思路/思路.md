1. 将语音中的预训练模型 + adapter，这个过程中 freeze 预训练的模型的参数，而只是训练加入的一个单独的子模块
2. self supervised 的 方法中，pretext task 其实可以有很多种改进的方法
3. 虚假语音检测：
	1. vocoder 数据增强，
	2. 将语音的 音色信息作为一个额外的输入，或许可以提高性能，比如添加一个额外的 pitch classifier，来单独判断音频的真假，然后训练的时候用两个 loss
4. 看一下Hinton之前提出的 FFNet 和最近的 In-Context learning
5. 新的 数据增强、损失函数 方法
6. 数据蒸馏
7. 语音自监督学习中，用 diffusion 来生成 discrete token？
8. wavlm + one-class learning

ASSOC: exploring lightweight and robust Audio anti-Spoofing with Self-supervised representation and One Class learning
1. 加入 adapter 来确保性能和减少参数
2. 探索不同层的特征 + one class learning 的效果
3. 探索加权特征 + one class 的效果