
> DARTS：神经网络架构搜索算法，架构和参数同时进行梯度下降来优化

1. 将 DARTS 用于深伪和欺诈检测
2. 优点：学习速度快、不需要人工干预、甚至参数量更少


## Introduction

1. 现在很多端到端的未来大部分重点都在前端的特征选择
2. 本文 首先探索了 neuro-evolution for augmenting topologies（NEAT）的使用，它可以自动学习神经网络架构，但是性能不咋地。
3. 于是作者转向了 neural architecture search （NAS），其一个特定的变体结构为 DARTS 能够从具有连续和可学习权重的搜索空间中选择候选动作，从而选择模型体系结构。
4. 由 DARTS 产生的网络类似于反欺骗技术的 SOTA，因此本文报告了使用（PC-DARTS）DARTS变体进行反欺骗。

## 相关工作和目标

DARTS 已经被用于 关键词检测、语音识别、说话人验证等任务并取得了较好的性能。

本文目标：
1. 判断 PC-DARTS 自动学习的神经架构是否能够与手工制作的网络相竞争
2. 试图确定此类网络的长期范围，甚至超越 SOTA
3. 了解自动学习和优化的解决方案是否更有效

## PC-DARTS

> 这里主要讲了 DARTS 的基本原理，暂时略过


## 实验


## 结果


3. 和 SOTA 系统进行对比：![[Pasted image 20221102100638.png]]可以看到，最好的模型 PC-DARTS(16,64) 比baseline 效果更好，且优于除 Res2Net 之外的模型。 