<!--
 * @Description: 
 * @Autor: 郭印林
 * @Date: 2022-08-10 13:46:04
 * @LastEditors: 郭印林
 * @LastEditTime: 2022-08-10 14:34:00
-->
## Developing real-time streaming transformer transducer for speech recognition on large-scale dataset 笔记

1. 结合 Transformer-XL and chunk-wise 处理方法，设计 Streamable Transformer Transducer（T-T）


### Introduction
1. 现有流式方法及其缺点：
    + Time-restricted 法，对左边和右边的context进行mask，缺点是层数的增加引入很大的延迟
    + chunk-wise 法：把输入语音分成几个 chunks，每个 chunks 分别做识别，，缺点是精度下降
    + Memory based 法：引入上下文向量编码历史信息，同时结合chunk-wise方法减少运行时间，缺点是破坏了Transformer的并行性，训练时间更长了
2. 本文目标是实现  streaming Transformer and Conformer Transducer 模型，在训练时间、推理时间和精度上达到平衡。
    + 结合 Transformer-XL and chunk-wise 处理方法
    + chunks 之间没有 overlap
    + 在 360ms 的look ahead 情况下，CPU上的 RTF 为 0.25

### 模型 
1. 采取的还是RNN-T的结果，只不过是 transformer 为 encoder，LSTM 为 predictor
2. 已有实验证明，相对位置嵌入效果比绝对位置嵌入好
3. 采用了Conformer中的结构，把 depth-wise CNN 变成 causal depth-wise CNN 来减少延迟

