- [x] FreGrad- Lightweight and Fast Frequency-aware Diffusion Vocoder
- [x] Matcha-TTS- A fast TTS architecture with conditional flow matching
- [x] Period VITS- Variational Inference with Explicit Pitch Modeling for End-to-end Emotional Speech Synthesis
- [x] DiffProsody- Diffusion-based Latent Prosody Generation for Expressive Speech Synthesis with Prosody Conditional Adversarial Training
- [ ] Hierarchical Prosody Modeling for Non-Autoregressive Speech Synthesis
- [ ] NaturalSpeech 3: Zero-Shot Speech Synthesis with Factorized Codec and Diffusion Models
- [ ] Expressive TTS Training with Frame and Style Reconstruction Loss
- [ ] PauseSpeech: Natural Speech Synthesis via Pre-trained Language Model and Pause-based Prosody Modelin
- [ ] Meta-StyleSpeech : Multi-Speaker Adaptive Text-to-Speech Generation
- [ ] Disentangling Style and Speaker Attributes for TTS Style Transfer
- [ ] PITS: Variational Pitch Infer- ence without Fundamental Frequency for End-to-End Pitch-controllable TTS
- [ ] TriniTTS: Pitch-controllable End-to-end TTS without External Aligner
- [ ] ParaTTS: Learning Linguistic and Prosodic Cross-Sentence Information in Paragraph-Based TTS
- [ ] Phone-Level Prosody Modelling with GMM-Based MDN for Diverse and Controllable Speech Synthesis
- [ ] Language Model-Based Emotion Prediction Methods for Emotional Speech Synthesis Systems
- [ ] HiFiDenoise: High-Fidelity Denoising Text to Speech with Adversarial Networks
- [ ] HiddenSinger: High-Quality Singing Voice Synthesis via Neural Audio Codec and Latent Diffusion Models
- [x] EMOQ-TTS: Emotion Intensity Quantization for Fine-Grained Controllable Emotional Text- to-Speech
- [x] EmoSpeech: Guiding FastSpeech2 Towards Emotional Text to Speech
- [x] Emodiff: Intensity controllable emotional text-to-speech with soft-label guidance
- [ ] Adaspeech 4: Adaptive text to speech in zero-shot scenarios
- [ ] Emotional voice con- version: Theory, databases and esd
- [ ] Unsupervised word-level prosody tagging for controllable speech synthesis
- [ ] Msemotts: Multi- scale emotion transfer, prediction, and control for emotional speech synthesis
- [ ] Speech synthesis with mixed emotions
- [ ] BDDM: Bilateral denoising diffusion models for fast and high-quality speech synthesis
- [ ] Guided-tts: A diffusion model for text-to-speech via classifier guidance
- [ ] OverFlow: Putting flows on top of neural transducers for better TTS
- [x] EmoMix: Emotion Mixing via Diffusion Models for Emotional Speech Synthesis
- [x] EMOCONV-Diff: Diffusion-Based Speech Emotion Conversion for Non-Parallel and in-the-Wild Data
- [ ] Diffusion-Based Voice Conversion with Fast Maximum Likelihood Sampling Scheme
- [ ] Stylespeech: Self-Supervised Style Enhancing with VQ-VAE-Based Pre-Training for Expressive Audiobook Speech Synthesis
- [ ] In-the-wild Speech Emotion Conversion Using Disentangled Self-Supervised Representations and Neural Vocoder-based Resynthesis
- [ ] DelightfulTTS: The Microsoft Speech Synthesis System for Blizzard Challenge 2021
- [ ] DelightfulTTS 2: End-to-End Speech Synthesis with Adversarial Vector-Quantized Auto-Encoders
- [x] Self-supervised Context-aware Style Representation for Expressive Speech Synthesis
- [ ] Boosting fast and high-quality speech synthesis with linear diffusion
- [x] VoiceFlow- Efficient Text-to-Speech with Rectified Flow Matching
- [ ] Explicit Intensity Control for Accented Text-to-speech