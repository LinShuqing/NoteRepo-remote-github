> 2022 年 1 月

1. 提出 LaMDA，是一个基于 Transformer 的、专门用于对话的语言模型
2. 有 137B 参数，采用 1.56T word 进行预训练
3. 在安全性方面，使用一组基于人类价值观的度量来量化安全性，通过少量的带有注释的数据进行 fine tune ，对 LaMDA 的输出进行过滤可以提高安全性
4. 通过使模型可以参考外部的知识源，如检索系统、翻译系统、计算器等，可以提高回答的真实性，同时也使用了 groundedness metric 来进行量化

## Introduction（略）

## 相关工作（略）

## LaMDA 预训练

LaMDA 预训练用于预测文本数据集中的下一个 token，和先前的对话模型仅对对话数据进行训练不同，LaMDA 还从 公共的 web 文档进行预训练，所以还可以作为一个通用的语言模型（ fine tune 之前）。

预训练的数据集包含 2.97B 文档、1.12B 对话 和 13.39B 个对话的句子，总计 1.56T 个单词。采用 BPE 作为 token，词表大小为 32K。

最大的模型有 137B 个参数，使用 Transformer 的 decoder 作为基本架构，64 层，dmodel = 8192, dff = 65536, h = 128, dk = dv = 128，不同模型结构如下：![[Pasted image 20230305152451.png]]

最大的模型在 1024 个 TPU-v3 芯片训练 57.7 天，每个 batch 包含 256K token。

![[Pasted image 20230305152544.png]]
预训练的时候，当成是一个标准的语言模型。

## 指标
> 描述评估生成模型的一些指标。

### 基本指标：质量（SSI）、安全性 和 真实性
质量包括：敏感性、特异度和趣味性。

敏感度，衡量一个模型的反应在上下文中是否有意义，并且与之前所说的任何内容都不矛盾。但是不能仅靠 敏感性来评估，因为模型会倾向于，用“我不知道”回答每个问题，用“好”回答每个语句。

特异性，用来衡量一个反应是否特定于给定的环境。例如，如果用户说“我喜欢Eurovision”，而模型回答“我也是”，那么它的特异性得分为0，因为这种回答可以用于许多不同的环境。如果它回答“我也是。我喜欢欧洲电视台的歌曲”，那么这个回答得分1。

趣味性被通过 0/1 标签来衡量，如果测试人员他们判断回答可能 “吸引某人的注意力”或“引起他们的好奇心”，或者如果它是意外的、机智的或有洞察力的，那么这个回答会得分1。

安全性：设计了一个新的安全度量来衡量不安全的模型输出，遵循 Google’s AI Principles。

真实性：目标是确保LaMDA在任何可能的情况下都能产生与有已知来源的回答，避免一本正经的胡说八道。将真实度定义为，有权威的信息源支持的回答所占的百分比。定义信息度为，携带已知来源信息的回答占所有回答的百分比。定义引用准确度为，引用其来源URL的回答在所有对外部世界有明确声明的回答中所占的百分比。

### 角色扮演指标：帮助性和一致性
测试对话时，让模型扮演特定的角色，
帮助性：：如果模型的回答包含基于用户使用信息检索系统进行的独立研究的正确信息，并且用户认为它们有用，则该模型的响应被标记为有用。

角色一致性：如果模型的回答看起来像目标角色所说的话，那么这个回答就被标记为满足角色一致性。

## LaMDA fine tune

### 对 SSI 和 安全性 的 生成式和判别式 fine tune
生成式 fine tune 是指用 预训练的模型，根据给定上下文生成特定文本。
判别式 fine tune 是指用 预训练的模型，评估生成的文本的质量和安全性。

生成式的 fine tune 表示为：context-sentinel-response，损失仅在 response 部分计算。

判别式的 fine tune 表示为：context-sentinel-response-attribute-name- rating，损失仅在 rating 部分计算，例子：
![[Pasted image 20230305160557.png]]
具体操作上，首先 fine tune LaMDA 来生成候选的回答，然后过滤出满足安全性的回答，对得到的回答根据 SSI 指标进行排序。将排名最好的回答作为下一个回答的输入。

### 通过 fine tune 来学习调用外部信息检索系统
LaMDA等语言模型倾向于生成看似合理的输出，但其实与事实相矛盾（比如捏造虚假的新闻）。

本文提出，通过学习 参考外部知识源 和 使用工具 来进行 fine tune。

#### toolset
创建了一个包含信息检索系统、计算器和翻译系统的工具集（toolset）。数据集的数据表示一个问题，标签表示这个问题的答案。比如说
+ 如果输入 135+7721，那么其对于的标签为 7856
+ 如果输入 hello in French，那么其对于的标签为 Bonjour
+ 如果输入 How old is Rafael Nadal?，标签为 Rafael Nadal / Age / 35
同时这个 set 还可以获得网络中的开放内容，然后解析成一个训练的样本。

#### 对话收集
收集真实的人类对话数据，且主要关注交互式的信息获取。
fine tune 的过程分两步，第一步进行 多轮对话，获得 base model 的输出，然后 base model 生成一个特殊的 TS 字符，表明接下来的文本是 查询 用途，且需要被送入 toolset。
第二步接受 tool 返回的输出和对话的内容，用于预测最终的真实的输出。这个任务也可以输出一个额外的 research query，在推理阶段，模型的输出要么送到信息检索系统，要么送给用户。
![[Pasted image 20230305163228.png]]