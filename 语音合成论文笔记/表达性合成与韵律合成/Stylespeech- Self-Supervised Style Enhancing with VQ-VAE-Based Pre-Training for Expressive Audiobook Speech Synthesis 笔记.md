> ICASSP 2024，CUHK、清华、微软
<!-- 翻译 & 理解 -->
<!-- The expressive quality of synthesized speech for audiobooks is lim- ited by generalized model architecture and unbalanced style dis- tribution in the training data. To address these issues, in this pa- per, we propose a self-supervised style enhancing method with VQ- VAE-based pre-training for expressive audiobook speech synthesis. Firstly, a text style encoder is pre-trained with a large amount of un- labeled text-only data. Secondly, a spectrogram style extractor based on VQ-VAE is pre-trained in a self-supervised manner, with plenty of audio data that covers complex style variations. Then a novel ar- chitecture with two encoder-decoder paths is specially designed to model the pronunciation and high-level style expressiveness respec- tively, with the guidance of the style extractor. Both objective and subjective evaluations demonstrate that our proposed method can ef- fectively improve the naturalness and expressiveness of the synthe- sized speech in audiobook synthesis especially for the role and out- of-domain scenarios.1 -->
1. 用于 audiobooks 的语音合成的表达质量受限于 模型架构 和训练数据中不平衡的风格分布
2. 提出基于 VQ-VAE 预训练的自监督风格增强方法，用于表达性的有声读物语音合成。首先，使用大量未标记的纯文本数据对文本风格编码器进行预训练。其次，基于 VQ-VAE 的频谱风格提取器以自监督方式进行预训练，使用覆盖复杂风格变化的大量音频数据。然后，设计了一种新颖的架构，具有两个编码器-解码器路径，专门用于分别建模发音和高级风格表现力，同时受到风格提取器的指导。客观和主观评估都表明，我们提出的方法可以有效地提高合成语音的自然性和表现力，特别是对于角色和域外场景
