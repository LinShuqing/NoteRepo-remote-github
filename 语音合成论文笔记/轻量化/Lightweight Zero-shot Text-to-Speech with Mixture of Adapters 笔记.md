> Interspeech 2024，NTT
<!-- 翻译 & 理解 -->
<!-- The advancements in zero-shot text-to-speech (TTS) meth- ods, based on large-scale models, have demonstrated high fi- delity in reproducing speaker characteristics. However, these models are too large for practical daily use. We propose a lightweight zero-shot TTS method using a mixture of adapters (MoA). Our proposed method incorporates MoA modules into the decoder and the variance adapter of a non-autoregressive TTS model. These modules enhance the ability to adapt a wide variety of speakers in a zero-shot manner by selecting appropri- ate adapters associated with speaker characteristics on the ba- sis of speaker embeddings. Our method achieves high-quality speech synthesis with minimal additional parameters. Through objective and subjective evaluations, we confirmed that our method achieves better performance than the baseline with less than 40% of parameters at 1.9 times faster inference speed. -->
1. 提出采用 mixture of adapters (MoA) 的 TTS：
    1. 将 MoA 引入到非自回归 TTS 模型的 decoder 和 variance adapter 中
    2. 通过选择与 speaker embeddings 相关的 adapters 来增强 zero-shot 能力
2. 可以在保持高质量语音合成的同时，减少参数量，提高推理速度

## Introduction
<!-- Advancements in text-to-speech (TTS) synthesis have enabled high-quality natural-sounding speech generation by leveraging large amounts of single and multi-speaker speech data [1–3]. This has facilitated the development of TTS for diverse speak- ers using a minimal amount of target-speaker utterances. This capability extends to zero-shot scenarios in which the acoustic model can adapt without retraining [4–6]. Following the suc- cesses of large-scale language models [7] in zero-shot and few- shot adaptation, zero-shot TTS methods have achieved high fi- delity by using large-scale models [5, 8]. However, these meth- ods are not well-suited for daily applications such as conversa- tion robots, virtual assistants, and personalized TTS services, as they can not run on edge devices such as smartphones due to their substantial parameter sizes. While there is a demand, syn- thesizing high-quality speech under a zero-shot condition with a lightweight TTS model remains an ongoing challenge. Achiev- ing this presents a significant challenge, as it requires maintain- ing the modeling capability to capture the diverse characteristics of thousands or more speakers with a model that has limited ex- pressiveness due to its constrained number of parameters. -->
