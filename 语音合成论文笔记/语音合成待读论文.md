
语音合成经典论文阅读列表：
- [x] deep voice 系列
- [x] tacotron 系列
- [ ] Parallel tacotron
- [x] fast speech 系列
- [x] Transformer-TTS
- [x] VITS
- [ ] ClariNet
- [x] DurIAN
- [ ] Diff-TTS
- [x] Grad-TTS
- [x] Glow-TTS
- [ ] Flow-TTS
- [ ] PortaSpeech
- [ ] ProDiff
- [ ] FastDiff
- [x] Diff-Wave
- [x] DiffGAN-TTS
- [ ] Diffsound（！！！）
- [ ] Guided-TTS 系列
- [ ] WaveGrad 系列（！！！）
- [ ] BDDM（！！！）
- [ ] CRASH
- [ ] Char2Wav
- [ ] EfficientTTS
- [ ] ItôTTS
- [ ] EdiTTS
- [ ] NoreSpeech
- [x] InstructTTS（！！！）
- [ ] SPEAR-TTS （！！！）
- [ ] ViT-TTS
- [ ] U-DiT TTS
- [ ] Mega-TTS
- [ ] StyleTTS 系列（！！！）
- [ ] DiCLET-TTS
- [ ] LightGrad
- [ ] MusicLDM
- [x] UniCATS
- [ ] DiffVoice
- [x] VQTTS
- [x] prompt TTS 系列
- [ ] 综述
	- [ ] An investigation into the adaptability of a diffusion-based TTS model
	- [ ] Comparing normalizing flows and diffusion models for prosody and acoustic modelling in text-to-speech
- [ ] 对齐
	- [ ] Montreal Forced Aligner
	- [x] Monotonic Alignment Search 
	- [ ] Monotonic Chunkwise Attention
	- [ ] Monotonic Attention
	- [x] Monotonic Alignments
- [ ] 声码器
	- [x] WaveNet
	- [x] MelGAN
	- [x] WaveGAN
	- [x] WaveRNN
	- [ ] SampleRNN
	- [x] WaveGlow
	- [ ] Parallel WaveGAN
	- [x] HiFi-GAN
	- [x] DiffWave
	- [ ] WaveFlow
	- [x] Multiband WaveRNN
	- [ ] FFTNet
	- [x] LPCNet
	- [x] LVCNet
	- [ ] ParaNet
- [x] 其他
	- [x] 评估指标
		- [x] PESQ
		- [x] MOS
	- [ ] probability of voice (POV)？
	- [ ] Generative Speech Coding with Predictive Variance Regularization
	- [ ] Neural analysis and synthesis: Reconstructing speech from self-supervised representations（NIPS）
- [x] 基本原理
	- [x] diffusion
	- [x] SDE
	- [x] score matching
	- [x] flow
	- [x] VAE

语音转换
- [x] StarGAN-VC 系列
- [x] MWDLP


歌声合成
- [x] DiffSinger
- [ ] DurIAN-SC
- [ ] Learning the Beauty in Songs: Neural Singing Voice Beautifier


VQ+Diffusion 调研：
- [x] Vector Quantized Diffusion Model for Text-to-Image Synthesis
- [x] Improved Vector Quantized Diffusion Models
- [x] Argmax flows and multinomial diffusion- Towards non-autoregressive language models
- [x] Structured denoising diffusion models in discrete state-spaces
- [ ] Discrete Contrastive Diffusion for Cross-Modal and Conditional Generation（16）
- [x] Global Context with Discrete Diffusion in Vector Quantised Modelling for Image Generation（CVPR 2022，19）
- [ ] Diffusion bridges vector quantized Variational AutoEncoders（8）
- [ ] Regularized Vector Quantization for Tokenized Image Synthesis（3）
- [ ] Spiking-Diffusion: Vector Quantized Discrete Diffusion Model with Spiking Neural Networks（preprint）
- [ ] Q-Diffusion: Quantizing Diffusion Models（12，ICCV 2023）


可控生成+韵律建模+离散化

歌声虚假检测？

code switch TTS ？

VIE（emotional/expressive）S？

情感识别的论文？

text encoder + f0 encoder + duration encoder + energy encoder 得到最终的 style embedding，然后进行聚类（但是需要无监督学习啊？！）

把文本作为 VAE 的 condition 来建模 style？

要实现一个真正好的语音 LM，需要文本的信息。
因为文本到语音的映射是一到多的，960 小时的语音对应的文本用来训练 word embedding 的效果很差，因为数据量太少！
文字的辅助是必要的！
可以启发 TTS？

## VITS

> multilingual、

1. 多语言、vocab + language id
2. loss
3. text encoder 用 GNN
4. d-vector 提取 speaker embedding