> ICML 2023，University of Surrey
<!-- 翻译 & 理解 -->
<!-- Text-to-audio (TTA) systems have recently gained attention for their ability to synthesize general au- dio based on text descriptions. However, previ- ous studies in TTA have limited generation qual- ity with high computational costs. In this study, we propose AudioLDM, a TTA system that is built on a latent space to learn continuous audio representations from contrastive language-audio pretraining (CLAP) embeddings. The pretrained CLAP models enable us to train LDMs with au- dio embeddings while providing text embeddings as the condition during sampling. By learning the latent representations of audio signals with- out modelling the cross-modal relationship, Au- dioLDM improves both generation quality and computational efficiency. Trained on AudioCaps with a single GPU, AudioLDM achieves state- of-the-art TTA performance compared to other open-sourced systems, measured by both objec- tive and subjective metrics. AudioLDM is also the first TTA system that enables various text- guided audio manipulations (e.g., style transfer) in a zero-shot fashion. Our implementation and demos are available at https://audioldm. github.io. -->
1. TTA 根据文本描述合成音频
2. 提出 AudioLDM，从 CLAP 中学习连续音频表征
3. AudioLDM 通过学习音频信号的潜在表示而不是建模跨模态关系，从而提高了生成质量和计算效率
4. 在单个 GPU 上训练，在 AudioCaps 上实现了 SOTA

## Introduction
<!-- Generating sound effects, music, or speech according to per- sonalized requirements is important for applications such as augmented and virtual reality, game development, and video editing. Traditionally, audio generation has been achieved through signal processing techniques (Andresen, 1979; Karplus & Strong, 1983). In recent years, generative models (Oord et al., 2016; Ho et al., 2020; Song et al., 2021; Tan et al., 2022), either unconditional or condi- tionedonothermodalities(Kreuketal.,2022;Z ̇elaszczyk & Man ́dziuk, 2022), have revolutionized this task. Previ- ous studies primarily worked on the label-to-sound setting with a small set of labels (Liu et al., 2021b; Pascual et al., 2022) such as the ten sound classes in the UrbanSound8K dataset (Salamon et al., 2014). In comparison, natural lan- guage is considerably more flexible than labels as they can include fine-grained descriptions of audio signals, such as pitch, acoustic environment, and temporal order. The task of generating audio prompted with natural language descrip- tions is known as text-to-audio (TTA) generation. -->
