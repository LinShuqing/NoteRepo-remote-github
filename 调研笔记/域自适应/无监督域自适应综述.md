> APSIPA Transactions on Signal and Information Processing

1. 深度学习需要：
	1. 大量有标记的数据集
	2. 训练数据和测试数据是独立同分布的（i.i.d.）
2. 导致在未知域上的性能无法保证，尤其是针对 OOD 的数据
3. 无监督自适应（UDA）利用有标记的源数据和未标记的目标域数据来实现目标域中的任务，在图像处理、视频分析、NLP、时间序列分析等多方面都有很多进展

## Introduction

1. 深度学习受数据分布的变化的影响，即存在所谓的 域偏移，对于 分布外 （OOD） 数据（源分布和目标分布不同），模型性能可能严重下降
2. UDA 是一种可行的解决方案，将从有标记数据的源域学习的知识迁移到未知的目标域：![[Pasted image 20230413152225.png]]
3. 域自适应可以看成迁移学习的有标记数据仅在源域的一种特殊情况：![[Pasted image 20230413152543.png]]
4. 本文旨在从理论和实践角度给出 UDA 的模型和算法，同时比较了不同的技术，重点在于基于深度学习的 UDA。

## Overview

在 UDA 中，源于分布记为 $p_s(x, y) \in p_{\mathcal{S}}$，然后一个不同的目标域记为 $p_t(x, y) \in p_{\mathcal{T}}$，有标记的数据集 $\mathcal{D}_{\mathcal{S}}$ 来自于源分布，无标记数据集 $\mathcal{D}_{\mathcal{T}}$ 来自于目标分布的边缘分布 $p_t(x)$，UDA 的目标是，通过同时在 $\mathcal{D}_{\mathcal{S}}, \mathcal{D}_{\mathcal{T}}$ 中学习，以提高在源域中训练的模型的泛化性。

记 $\mathcal{Y}=\{1,2, \ldots, c\}$ 是分类任务的标签，$\mathcal{Y}$ 也可以是生成任务中连续的值。UDA 基于以下假设：

对于假设 $h$：$$\begin{aligned}
& \mathcal{L}_t(h) \leq \mathcal{L}_s(h)+d\left[p_{\mathcal{S}}, p_{\mathcal{T}}\right]+ \\
& \min \left[\mathbb{E}_{x \sim p_s}\left|p_s(y \mid x)-p_t(y \mid x)\right|, \mathbb{E}_{x \sim p_t}\left|p_s(y \mid x)-p_t(y \mid x)\right|\right]
\end{aligned}$$
其中，$\mathcal{L}_t(h),\mathcal{L}_s(h)$ 是在假设 $h$ 下在目标域和源域的损失，$d[\cdot]$ 表示 散度测度（如 JS 散度）  ，第三项 $\min \left[\mathbb{E}_{x \sim p_s}\left|p_s(y \mid x)-p_t(y \mid x)\right|, \mathbb{E}_{x \sim p_t}\left|p_s(y \mid x)-p_t(y \mid x)\right|\right]$ 是一个可以忽略的值，从而源域中的损失+域之间的散度可以看成是目标域损失的上界，源域损失可以通过有监督的模型训练来进行优化，那么最终 UDA 的目标就是最小化两个域之间的**散度**。

域偏移可以分为四类：![[Pasted image 20230413164348.png]]
本文主要关注 UDA 中的 covariate shift。

## 方法

目前流行的方法的汇总：![[Pasted image 20230413164819.png]]

### Statistic Divergence Alignment（SDA）

想法就是，学习域不变的特征，也就是最小化 latent space 中不同域之间的差异，核心思想就是选择一个测度来量化这种差异，即 divergence measure，如 MMD（Maximum Mean Discrepancy） 、correlation alignment 、contrastive domain discrepancy、Wasserstein distance、graph matching loss 等等。

MMD 计算观察样本的分布差异，即通过比较两个域的 smooth function 的平均值，值越大表示差异越大。通常将 RKHS 空间中的单位球作为 smooth function，当两个分布相同时，函数值为 0 。然后还有一个 alignment component，其目标是分类，计算 MMD 并将其最小化，最终的目标是对齐源域和目标域。
>有两个分布的样本，通过寻找在样本空间上的一个映射函数 $f$，求两个分布的样本在 $f$ 上的函数值的均值，通过把两个均值作差可以得到两个分布在 $f$ 下的 mean discrepancy。寻找一个 $f$ 使得这个 mean discrepancy 有最大值，就得到了MMD。
>最后取MMD作为检验统计量（test statistic），从而判断两个分布是否相同。如果这个值足够小，就认为两个分布相同，否则就认为它们不相同。更加简单的理解就是：求两堆数据的均值的距离。
>![[Pasted image 20230413193731.png]]

CORAL 被定义为两个域的特征之间的二阶统计量差异，其实就是协方差。

CDD 将 label 纳入到 MDD，通过最小化 CDD，不同类之间的差异变大，同类之间的差异变小。而如果标签缺失，则采用 对比自适应网络（CAN）来估计标签，然后再最小化 CDD。

Wasserstein距离（也被称为最优传输距离）也可以用于测量分布之间的差异。

graph matching（图匹配）旨在找到两个图之间的最佳对应关系，对于一批样本，特征提取可以被视为无向图中的节点。两个节点之间的距离表示它们的相似性。域差异被定义为源和目标域构成的图之间的 match cost。

### Adversarial Learning

前面的方法是手动选度量，其实可以自适应地学习这个度量。

根据前面的公式，为了最小化目标域损失的上界（不等号右边），对抗 UDA 通过采用判别器来公式中的最小化域差异项：![[Pasted image 20230413193744.png]]
特征提取器 $f(\cdot)$ 用于提取特征 $f(x) \in \mathbb{R}^K$，我们希望 $d\left[p_s(f(x)), p_t(f(x))\right]$ 尽可能地小。也就是说，除了要训练分类器能够正确的对源数据进行分类，$f(\cdot)$ 要优化以使得源分布和目标分布尽可能地相似。这个过程主要通过一个有监督的域判别器来实现，$\mathbb{R}^K \rightarrow(0,1)$，总的来说，三个模块的目标函数定义为：$$\begin{array}{ll}
\max _{C l s}^{\max } & \underset{x \sim p_s}{\mathbb{E}} \log C(f(x), y) \\
\max _{D i s} & \underset{E}{\mathbb{E}} \ln \log (1-\operatorname{Dis}(f(x))+\underset{x \sim p_t}{\mathbb{E}} \log \operatorname{Dis}(f(x)). \\
\max _f & \underset{x \sim p_s}{\mathbb{E}} \log C(f(x), y)+\lambda_{x \sim p_t}^{\mathbb{E}} \log (1-\operatorname{Dis}(f(x)),
\end{array}$$
其中，$\lambda \in \mathbb{R}^{+}$ 用于平衡两个损失。
> 分类器和在源域训练差不多，目标是尽可能准确地分类源域数据。
> 判别器用于判断特征是来自源域还是目标域
> 特征提取器 $f$ 这里有两个目的，一个是尽可能欺骗判别器，来生成在源域和目标域之间有着较少差异的特征，另一个目的是输入好的特征来给分类器使其可以正确分类。

在具体的模型上，domain adversarial neural network (DANN) 采用所谓的梯度反转层作为判别器。adversarial discriminative domain adaptation (ADDA) 通过源域训练初始的目标模型，然后进行对抗自适应，这相当于目标域特定分类器。

由于传统的对抗 UDA 中通常使用 JS 散度，但是 JS 散度对于两个完全不重叠的分布，其散度是一个固定值（也就是无法区分他们之间到底差多少。Wasserstein距离可以解决这种问题，同时也被用于 GAN 中，因此也有用于 估计Wasserstein距离 的判别器。

### Normalization Statistics

DNN 中，batch norm 通常可以实现更快的训练和更平滑的优化和更快的收敛，原因在于 BN 中有两个低阶统计量，即均值和方差，以及两个高阶的可学习的统计量，即缩放因子和偏置（scale，bias）。

早期的一些工作把 BN 用于DA，AdaBN 在把模型用于目标域的时候，除了 BN 层其他的参数都是直接用源域的；AutoDIAL 用于泛化 AdaBN，通过一个额外的 domain alignment layers 来重新训练网络的权重：![[Pasted image 20230413195901.png]]

### Generative Domain Mapping

前面的方法是在 latent space 中对齐特征，也可以在原始数据上直接对目标域的数据进行映射。网络就可以在生成的目标域的数据（来自于源域）上进行训练，此外，网络也可以同时和 GAN 进行训练：![[Pasted image 20230413201146.png]]
> 意思就是，训练一个 style translator，将源域和目标域的数据尽可能地靠近，然后就和之前一样，一个判别器用于区分源域和目标域，一个分类器用于对转换后的源域数据进行分类。
> 完成训练后，直接将目标域的数据输入到分类器中即可进行分类。
> 原理有点类似于 cyclegan。
> 其实如果不做分类任务的话，这个目标就和图像风格转换差不多了。

### Self-training

self-training 是一种训练方案，利用未标记的目标域数据来实现域自适应，self training 是一个 “回合制” 的训练策略，有两步：
1. 在目标域中生成伪标签
2. 使用生成的伪标签和数据来训练网络
> 具体来说：
> 	+ 利用已标记的数据来训练一个好的模型，然后使用这个模型对未标记的数据进行标记。
> 	+ 进行伪标签的生成，因为我们知道，已训练好的模型对未标记数据的所有预测都不可能都是好的，因此对于经典的 Self-training，通常是使用分数阈值（confidence score）过滤部分预测，以选择出未标记数据的预测标签的一个子集。
> 	+ 将生成的伪标签与原始的标记数据相结合，并在合并后数据上进行联合训练。
> 	+ 整个过程可以重复 n 次，直到达到收敛。
> 效果还挺好的，有些已经超过了 基于对抗训练的方法。

这其中一个比较重要的问题是，伪标签的噪声往往很大从而导致标签不可靠。很多论文都是专注于解决这个问题。

### Self-supervision

UDA 的另一个解决方法是，在训练时引入辅助的自监督任务，可以通过在源域分类+目标域重构来实现对齐，也可以同时在源域和目标域进行重构。然后通过重构损失优化重构网络。

### Low density target boundary

也有用半监督方法的，即基于聚类的 UDA，来自同一类的目标域样本一般在聚类上分布接近，从而目标域的分类决策界应该位于低密度区域。

## 应用

1. 图像：图像分类、图像检测、图像分割、图像生成
2. 医学图像处理
3. 视频分析
4. 自然语言处理
5. 时间序列分析

## 方向

