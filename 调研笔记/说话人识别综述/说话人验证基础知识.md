
GMM 模型原理

给定 $D$ 维的特征向量，用于似然函数的混合密度定义为：$$p(\vec{x} \mid \lambda)=\sum_{i=1}^M w_i p_i(\vec{x})$$
也就是 $M$ 个 多维高斯模型 $p_i(\vec{x})$ 的加权和，每个模型都包含一个 $D\times 1$ 的均值向量 $\vec{\mu}_i$ 和 一个 $D\times D$ 的协方差矩阵 $\sum_i$，即：$$p_i(\vec{x})=\frac{1}{(2 \pi)^{D / 2}\left|\sum_i\right|^{1 / 2}} e^{-(1 / 2)\left(\vec{x}-\vec{\mu}_i\right)^{\prime} \Sigma_i^{-1}\left(\vec{x}-\vec{\mu}_i\right)}$$
这里的权重满足 $\sum_{i=1}^M w_i=1$ （用来确保是概率分布），从而 $\lambda=\left(w_i, \vec{\mu}_i, \Sigma_i\right), i=(1, \ldots, M)$。

> 通常的协方差矩阵都是对角阵。

## 说话人验证

给定语音段 $Y$ 和假设的说话人 $S$ ，说话人验证问题本质是一个基本的假设检验问题：
+ $H_0$：$Y$ 来自于假设的说话人 $S$
+ $H_1$：$Y$ 不属于说话人 $S$
决定选择的最优检验是通过 似然比（SR）：$$\frac{p(Y \mid \mathrm{H} 0)}{p(Y \mid \mathrm{H} 1)} \begin{cases}>\theta, & \text { accept } \mathrm{H} 0 \\ <\theta, & \text { accept } \mathrm{H} 1\end{cases}$$
其中，$p(Y \mid \mathrm{H} 0)$ 为给定假设 $H_0$ 下语音 $Y$ 的似然，接受或者拒绝 $H_0$ 的阈值为 $\theta$。

> 这里如果只用一个模型然后判断阈值可以吗，实际上是不可以的，因为对于开集的说话人验证问题，测试的语音可能不属于模型库的任何一个人（也就是所谓的 imposter），这个时候直接拿它 claim 的那个说话人对应的模型来判断阈值可能会不准。
> 如果是 identification 就可以。


说话人验证的目标就是，设计检测系统，计算两个似然值然后根据阈值进行判断，如图：![[Pasted image 20230104194758.png]]

设前端处理后的输出，也就是测试语音段为 $X=\left\{\vec{x}_1, \ldots, \vec{x}_T\right\}$，其中 $\vec{x}_t$ 为离散时间的特征向量。然后使用特征向量计算两个假设的似然。从数学上来看，定义模型 $\lambda_{\mathrm{hyp}}$ 表示 $H_0$，在特征空间中代表假设的说话人 $S$。

>例如，如果说话人模型是高斯分布，则 $\lambda_{\mathrm{hyp}}$ 表示高斯分布的均值和协方差矩阵。

模型 $\lambda_{\overline{\mathrm{hyp}}}$ 表示替代假设 $H_1$，则似然比为 $p\left(X \mid \lambda_{\mathrm{hyp}}\right) / p\left(X \mid \lambda_{\overline{\mathrm{hyp}}}\right)$ ，但是通常采用对数似然比，定义为：$$\Lambda(X)=\log p\left(X \mid \lambda_{\mathrm{hyp}}\right)-\log p\left(X \mid \lambda_{\overline{\mathrm{hyp}}}\right)$$
用于假设 $H_0$ 的模型可以被很好的定义然后通过说话人 $S$ 的语音进行训练，但是模型  $\lambda_{\mathrm{hyp}}$ 很难被定义，因为它可能表征所有的假设说话人。有两个方法用来解决这个问题。

### 背景说话人

第一个方法是使用一组其他的说话人模型（这里不能包括 enrollment 阶段的说话人）来作为覆盖这个空间，称之为likelihood ratio sets、cohorts、background speakers 等不同名称。

给定一组 $N$ 个说话人的背景说话人模型 $\left\{\lambda_1, \ldots, \lambda_N\right\}$，备选假设模型定义为：$$p\left(X \mid \lambda_{\overline{\mathrm{hyp}}}\right)=f\left(p\left(X \mid \lambda_1\right), \ldots, p\left(X \mid \lambda_N\right)\right)$$
这里的 $f(\cdot)$ 为平均或者最大值函数。一般来说，要使这种方法获得最佳性能，需要使用特定说话人的背景说话人集，如果说话人很多，则为每个说话人设计一个单独的背景说话人集很麻烦。

### GMM-UBM

第二个方法是pool来自多个说话人的语音然后训练一个单独的模型，也就是所谓的 UBM 模型。训练一个单一的模型 $\lambda_{\mathrm{bkg}}$ 用来表征备选假设。这种方法的主要优点是，可以针对特定任务对单个说话人模型进行一次训练，然后将其用于该任务中的所有假设说话人。

在 GMM 自适应方法中，通过使用特定说话人的语音来调节 UBM 模型的参数来获得特定的说话人模型，这一过程可以采用 贝叶斯自适应或 MAP 估计。从而可以在说话人模型和背景模型之间实现更紧密的耦合，以得到更好的性能。

具体来说，自适应过程描述如下。给定背景模型和某个说话人的训练向量，首先确定训练向量到背景模型的高斯分量的 probabilistic alignment ：$$\operatorname{Pr}\left(i \mid \vec{x}_t\right)=\frac{w_i p_i\left(\vec{x}_t\right)}{\sum_{j=1}^M w_j p_j\left(\vec{x}_t\right)}$$
> 其实就是计算混合高斯模型的每个高斯分量的重要程度（以概率来表示）。

然后计算权重、均值和协方差的充分统计量：$$\begin{aligned}
n_i & =\sum_{t=1}^T \operatorname{Pr}\left(i \mid \vec{x}_t\right), \\
E_i(\vec{x}) & =\frac{1}{n_i} \sum_{t=1}^T \operatorname{Pr}\left(i \mid \vec{x}_t\right) \vec{x}_t, \\
E_i\left(\vec{x}^2\right) & =\frac{1}{n_i} \sum_{t=1}^T \operatorname{Pr}\left(i \mid \vec{x}_t\right) \vec{x}_t^2 .
\end{aligned}$$
> 其实就是 EM 算法的 E 步骤。

然后用上面的充分统计量来更新原来 UBM 的参数从而得到调整后的参数：$$\begin{gathered}
\hat{w}_i=\left[\alpha_i n_i / T+\left(1-\alpha_i\right) w_i\right] \gamma, \\
\hat{\vec{\mu}}_i=\alpha_i E_i(\vec{x})+\left(1-\alpha_i\right) \vec{\mu}_i, \\
\hat{\vec{\sigma}}_i^2=\alpha_i E_i\left(\vec{x}^2\right)+\left(1-\alpha_i\right)\left(\vec{\sigma}_i^2+\vec{\mu}_i^2\right)-\hat{\vec{\mu}}_i^2 .
\end{gathered}$$
其中，$$\alpha_i=\frac{n_i}{n_i+r}$$
$r$ 为固定的 相关因子。

## 因子分析（FA）

因子分析通过将观察到的变量表示为数量较少的互相独立的潜在变量（称为因子），来描述观察变量的内在模式。

> 其实有点像 embedding 提取，简单来说就是对数据进行降维。

假设 $p$ 个随机变量 $x_i$（注意这里的意思是 $p$ 个随机变量都来自于不同分布，不是同一个分布采用得到的值），其对应的均值为 $\mu_i$，将其偏离均值的变化表示为：$$x_i-\mu_i=L_{i 1} f_1+L_{i 2} f_2+\ldots+L_{i k} f_k+\epsilon_i$$
其中，$f_k$ 为因子，且 $k<p$，且对于 $p$ 个随机变量，这 $k$ 个因子是共享的。$\epsilon_i$ 为与每个 $x_i$ 有关的统计残差量，均值为0方差有限。用向量形式表示为：$$\boldsymbol{x}-\boldsymbol{\mu}=\boldsymbol{L}\boldsymbol{f}+\boldsymbol{\epsilon}$$
其中，$\boldsymbol{x},\boldsymbol{\mu},\boldsymbol{\epsilon} \in \mathbb{R}^{p\times 1},\boldsymbol{f}\in\mathbb{R}^{k\times 1},\boldsymbol{L}\in\mathbb{R}^{p\times k}$ 。
> 在语音中，这里的 $\boldsymbol{x}$ 相当于声学特征，如某一帧的 40 维度的 MFCC，则 $p=40$

如果有 $N$ 次观察 $\boldsymbol{x}_j$，则有 $N$ 个对应的 $\boldsymbol{f}_j$ 和 $\boldsymbol{\epsilon}_j$，但是 $\boldsymbol{\mu},\boldsymbol{L}$ 是观察独立的，这里的 $\boldsymbol{L}$ 称之为载荷矩阵。

### 联合因子分析（JFA）

将因子分析的方法用在 GMM-UBM 超向量中，对于一段语音，其通过 **UBM-自适应** 得到的超向量为 $\boldsymbol{s}$，假设 GMM 有 $M$ 个高斯分量，每个多维高斯分量的维度为 $K$（其实就是声学特征的维度，和前面的 $p$ 是一样的），则超向量 $\boldsymbol{s}\in\mathbb{R}^{MK\times 1}$。

联合因子分析认为，超向量 $\boldsymbol{s}$ 不仅包含了与说话人有关的信息，还包含了与信道有关的信息，因此可以分解如下：$$\boldsymbol{s}=\boldsymbol{m}+\boldsymbol{V}\boldsymbol{y}+\boldsymbol{U}\boldsymbol{x}+\boldsymbol{D}\boldsymbol{z}$$
其中
+ $\boldsymbol{m}$ 是与说话人无关的超向量，可以直接采用 UBM 模型的超向量（实际上可以看作因子分析中的均值向量），和 $\boldsymbol{s}$ 的维度相同
+ $\boldsymbol{y}$ 是低维的说话人信息因子，$\boldsymbol{V}$ 是对应的载荷矩阵，$\boldsymbol{V}$ 的每一列被称为本征音（eigenvoice）
+ $\boldsymbol{x}$ 是低维的信道信息因子，$\boldsymbol{U}$ 是对应的载荷矩阵，$\boldsymbol{U}$ 的每一列被称为本征信道（eigenchannel）
+ $\boldsymbol{z}$ 也是一个和 $\boldsymbol{s}$ 维度相同的残差项，称为公共因子，$\boldsymbol{D}$ 是对角方阵
> 之所以称之为联合因子分析，是因为它同时建模了说话人因子和信道因子。
> 联合因子分析的难点在于公式中矩阵的参数求解，涉及大量理论和公式。

完成联合因子分析之后，即可使用 $\boldsymbol{y}$ 或者加上 $\boldsymbol{z}$ 构建 SVM 进行说话人识别。

### i-vector

在 联合因子分析 中，将 GMM 超向量分解为公共因子 $\boldsymbol{z}$、说话人因子 $\boldsymbol{y}$ 和 信道因子 $\boldsymbol{x}$。在这个过程中，$\boldsymbol{x}$ 通常会包含一些说话人的信息从而弱化了 $\boldsymbol{y}$ 中的说话人信息。

于是 i-vector 将 JFA 公式中的 信道空间 $\boldsymbol{U}$ 和说话人空间 $\boldsymbol{V}$ 合二为一，得到一个所谓的 total variability 空间，用矩阵 $\boldsymbol{T}$ 表示。对应的因子称之为 total factor，用 $\boldsymbol{w}$ 表示：$$\boldsymbol{s}=\boldsymbol{m}+\boldsymbol{Tw}$$
$\boldsymbol{w}$ 是一个符合标准多元正太分布的随机向量，其维度通常选取在 400 到 600 之间，total factor $\boldsymbol{w}$ 也被称之为 身份向量 identity vector，简称就是 i-vector。

从另一个角度解释，随机向量 $\boldsymbol{s}$ 的均值向量为 $\boldsymbol{m}$，其协方差矩阵为 $\boldsymbol{T}\boldsymbol{T}^{T}$ ，是从标准正太分布进行变化而得到的。

由于是对信道和说话人进行同时建模，因子得到的 total factor 包含信道和说话人信息，为了移除信道的影响，需要对 i-vector 进行信道补偿。
> 这里可以看出，JFA 和 i-vector 的区别是，JFA 是在高维空间的超向量中移除信道的影响，而 i-vector 是在低维的 total factor 所在的空间移除信道的影响。

信道补偿的基本原理是，通过寻找投影矩阵 $\boldsymbol{A}$，使得补偿后的向量 $\boldsymbol{w}^\prime = \boldsymbol{Aw}$ 不包含信道信息，然后使用 $\boldsymbol{w}^\prime$ 进行后续的声纹识别，常用的补偿方法有以下三种：
+ 类内协方差正则化 WCCN
+ 线性判别分析 LDA
+ 扰动属性投影 NAP

> 在训练过程中，$\boldsymbol{s},\boldsymbol{m}$ 是通过训练数据求出来的，$\boldsymbol{T}$ 是针对每个说话人训练出来的。

$\boldsymbol{w}$ 其实是隐变量，可以通过给定语音的后验分布来定义，且该后验分布是一个高斯分布，其均值对应于 i-vector。假设 $L$ 帧语音 $\left\{y_1, y_2, \ldots, y_L\right\}$ ，UBM 模型 $\Omega$ 包含 $C$ 个多维高斯分布，每个分布的维度为 $F$，则计算：$$\begin{aligned}
& N_c=\sum_{t=1}^L \mathrm{P}\left(c \mid y_t, \Omega\right) \\
& F_c=\sum_{t=1}^L \mathrm{P}\left(c \mid y_t, \Omega\right) y_t
\end{aligned}$$
其中 $c=1, \ldots, C$ 为高斯分布的索引。$\mathrm{P}\left(c \mid x_t, \Omega\right)$ 表示生成 $y_t$ 的第 $c$ 个高斯分布的后验概率。为了估计 i-vector，计算：$$\tilde{F}_c=\sum_{t=1}^L \mathrm{P}\left(c \mid y_t, \Omega\right)\left(y_t-m_c\right)$$
其中，$m_c$ 为第 $c$ 个高斯分布的均值向量，则对于这一句话（或者说对于这 $L$ 帧语音），i-vector 计算为：$$w=\left(I+T^t \Sigma^{-1} N(u) T\right)^{-1} \cdot T^t \Sigma^{-1} \tilde{F}(u)$$
其中，$N(u)$ 为 $CF\times CF$ 的“对角阵”，每个对角块为 $N_c I(c=1, \ldots, C)$，$\tilde{F}(u)$ 为通过拼接 $\tilde{F}_c$ 得到的 $CF\times 1$ 的超向量。

### DNN-UBM

由于 GMM-UBM 的最终输入就是前面说的后验概率，可以通过 DNN 输入语音帧输出概率来建模，只要 DNN 的最后一层是 softmax 层就行。