
# Argmax Flows and Multinomial Diffusion- Learning Categorical Distributions

## Multinomial Diffusion

![](image/Pasted%20image%2020231008111747.png)

用于  categorical data。和之前的不一样，这里的 $\boldsymbol{x}_t$ 是 one-hot 格式的，即 $\boldsymbol{x}_t\in\{0,1\}^K$，对于类别 $k$，$x_k=1$，其他都为 $0$。
> 忽略了维度轴以简化，例如维度可能是 $h\times w\times K$，忽略了 feature map 维度 $h\times w$。

采用 categorical distribution  来定义 multinomial diffusion 的过程，其有 $\beta_t$ 的概率均匀采样一个类别：
$$q(\boldsymbol{x}_t|\boldsymbol{x}_{t-1})=\mathcal{C}(\boldsymbol{x}_t|(1-\beta_t)\boldsymbol{x}_{t-1}+\beta_t/K)$$
这里的 $\mathcal{C}$ 就代表  categorical distribution。
> 简单来说，有 $\beta_t$ 的概率从 $K$ 个类别中随机均匀采样，有 $1-\beta_t$ 的概率保持不变。注意这里并不是转移概率。

又因为满足马尔可夫链，从而：
$$q(\boldsymbol{x}_t|\boldsymbol{x}_0)=\mathcal{C}(\boldsymbol{x}_t|\bar{\alpha}_t\boldsymbol{x}_0+(1-\bar{\alpha}_t)/K)$$
其中，$\begin{aligned}\alpha_t=1-\beta_t\text{ and }\bar{\alpha}_t=\prod_{\tau=1}^t\alpha_\tau\end{aligned}$。

根据连续的 diffusion 的理论，我们通常计算后验 $q(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,\boldsymbol{x}_0)$，这里 categorical posterior 可以写为：
$$\begin{gathered}
q(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,\boldsymbol{x}_0) =\mathcal{C}(x_{t-1}|\boldsymbol{\theta}_{\mathrm{post}}(\boldsymbol{x}_t,\boldsymbol{x}_0)),\quad\mathrm{where}\quad\boldsymbol{\theta}_{\mathrm{post}}(\boldsymbol{x}_t,\boldsymbol{x}_0)=\tilde{\boldsymbol{\theta}}/\sum_{k=1}^K\tilde{\theta}_k \\
\tilde{\theta} =[\alpha_t\boldsymbol{x}_t+(1-\alpha_t)/K]\odot[\bar{\alpha}_{t-1}\boldsymbol{x}_0+(1-\bar{\alpha}_{t-1})/K]. 
\end{gathered}$$
> 

在原始的 DDPM 中，通常预测噪声。但是对于离散数据，预测噪声很困难，所以还是从 $\boldsymbol{x}_t$ 中为 $\hat{\boldsymbol{x}}_0$ 预测一个概率向量：$\hat{\boldsymbol{x}}_0=\mu{(\boldsymbol{x}_t,t)}$，总的来说：
$$p(\boldsymbol{x}_0|\boldsymbol{x}_1)=\mathcal{C}(\boldsymbol{x}_0|\hat{\boldsymbol{x}}_0)\mathrm{~and~}p(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t)=\mathcal{C}(\boldsymbol{x}_{t-1}|\boldsymbol{\theta}_{\mathrm{post}}(\boldsymbol{x}_t,\hat{\boldsymbol{x}}_0))\mathrm{~where~}\hat{\boldsymbol{x}}_0=\mu(\boldsymbol{x}_t,t)$$
> 简单来说，就是用神经网络预测不带噪声的样本 $\hat{\boldsymbol{x}}_0$，然后就和普通的 diffusion 一样，带入到 $q(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,\boldsymbol{x}_0)$ 中进行降噪。

此时损失函数中的 KL 散度计算为：
$$\mathrm{KL}\left(q(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,\boldsymbol{x}_0)|p(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t)\right)=\mathrm{KL}\left(\mathcal{C}(\boldsymbol{\theta}_{\mathrm{post}}(\boldsymbol{x}_t,\boldsymbol{x}_0))|\mathcal{C}(\boldsymbol{\theta}_{\mathrm{post}}(\boldsymbol{x}_t,\hat{\boldsymbol{x}}_0))\right),$$
而这两个 categorical 分布之间的散度进一步写为：
$$\sum_k\boldsymbol{\theta}_\mathrm{post}(\boldsymbol{x}_t,\boldsymbol{x}_0))_k\cdot\left.\log\frac{\boldsymbol{\theta}_\mathrm{post}(\boldsymbol{x}_t,\boldsymbol{x}_0))_k}{\boldsymbol{\theta}_\mathrm{post}(\boldsymbol{x}_t,\hat{\boldsymbol{x}}_0))_k}\right. $$

# Structured Denoising Diffusion Models in Discrete State-Spaces
> Google，NIPS 2021

1. 提出 Discrete Denoising Diffusion Probabilistic Models（D3PMs），是对 multinomial diffusion 的 generalization，通过采用均匀分布来实现加噪过程
2. 包含以下三种传输矩阵进行加噪：
	1. 模仿连续空间中的高斯核的矩阵
	2. 基于 embedding 空间最邻近思想的矩阵
	3. 引入 absorbing states 的矩阵
3. 表明了，传输矩阵的选择非常重要
4. 同时引入了一个新的损失函数，将变分下界和一个额外的交叉熵损失进行组合
5. 在文本和图像中进行了实验

## Introduction

1. [Argmax Flows and Multinomial Diffusion- Learning Categorical Distributions 笔记](../经典模型和算法/Argmax%20Flows%20and%20Multinomial%20Diffusion-%20Learning%20Categorical%20Distributions%20笔记.md) 中已经提出使用带有离散状态空间的  diffusion 模型，但是没有实验用于大规模的文本或图像合成的模型
2. 本文是离散 diffusion 的拓展，采用更 structured categorical corruption process 来塑造数据分布，如下图，
![](image/Pasted%20image%2020231009211639.png)


3. 同时还引入了一个新的辅助损失来稳定训练和一系列的 noise schedules 来提高性能

## 背景：diffusion

在 diffusion 中，加噪过程的分布 $q(\boldsymbol{x}_t|\boldsymbol{x}_{t-1})$ 理论上可以上任意的，而当这个分布满足以下条件是，我们才可以有效地训练其近似 $p_\theta$：
+ 可以从分布 $q(\boldsymbol{x}_t|\boldsymbol{x}_{t-1})$ 中进行高效的采样得到 $\boldsymbol{x}_t$，从而可以独立的优化 $L_{t-1}$ 这一项
+ 分布 $q(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,\boldsymbol{x}_0)$ 是可求的，从而可以计算损失函数中的 KL 散度

最近的工作都是定义在连续空间的，即 $q(\boldsymbol{x}_t|\boldsymbol{x}_{t-1})~=~\mathcal{N}(\boldsymbol{x}_t|\sqrt{1-\beta_t}\boldsymbol{x}_{t-1},\beta_t\boldsymbol{I})$，从而 $p_\theta(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t)=\mathcal{N}\left(\boldsymbol{x}_{t-1}|\boldsymbol{\mu}_\theta(\boldsymbol{x}_t,t),\boldsymbol{\Sigma}_\theta(\boldsymbol{x}_t,t)\right)$。

## 离散状态空间下的 diffusion 模型

其实 15 年最原始的那篇论文考虑了 binary random variables 下的 diffusion，后来 [Argmax Flows and Multinomial Diffusion- Learning Categorical Distributions 笔记](../经典模型和算法/Argmax%20Flows%20and%20Multinomial%20Diffusion-%20Learning%20Categorical%20Distributions%20笔记.md) 拓展到 categorial random variable，其传输矩阵为  uniform
transition probabilities。本文给出一个更通用的框架。

对于标量、离散随机变量，有 $K$ 类，即 $x_t,x_{t-1}\in1,\dots,K$，其 forward transition probabilities（前向转移概率）可以通过矩阵 $[\boldsymbol{Q}_{t}]_{ij}=q(x_{t}=j|x_{t-1}=i)$ 来表示，这里把 $x$ 拓展为 one-hot 的格式 $\boldsymbol{x}$，从而：
$$q(\boldsymbol{x}_t|\boldsymbol{x}_{t-1})=\mathrm{Cat}(\boldsymbol{x}_t;\boldsymbol{p}=\boldsymbol{x}_{t-1}\boldsymbol{Q}_t)$$
这里的 $\boldsymbol{p}$ 是一个长为 $K$ 的概率向量。
> 这里假设每个 token 之间是独立的。

从而整个过程中的边缘分布和后验分布为：
$$\begin{aligned}q(\boldsymbol{x}_t|\boldsymbol{x}_0)&=\mathrm{Cat}\left(\boldsymbol{x}_t;\boldsymbol{p}=\boldsymbol{x}_0\overline{\boldsymbol{Q}}_t\right),\quad\mathrm{with}\quad\overline{\boldsymbol{Q}}_t=\boldsymbol{Q}_1\boldsymbol{Q}_2\ldots\boldsymbol{Q}_t\\q(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,\boldsymbol{x}_0)&=\frac{q(\boldsymbol{x}_t|\boldsymbol{x}_{t-1},\boldsymbol{x}_0)q(\boldsymbol{x}_{t-1}|\boldsymbol{x}_0)}{q(\boldsymbol{x}_t|\boldsymbol{x}_0)}=\mathrm{Cat}\left(\boldsymbol{x}_{t-1};\boldsymbol{p}=\frac{\boldsymbol{x}_t\boldsymbol{Q}_t^\top\odot\boldsymbol{x}_0\overline{\boldsymbol{Q}}_{t-1}}{\boldsymbol{x}_0\overline{\boldsymbol{Q}}_t\boldsymbol{x}_t^\top}\right)\end{aligned}$$
那么假设 revere 过程也是每个独立的 token 之间的乘积，从而 KL 散度可以简单计算为，每个随机变量的某种和，也就是满足上面说的两个条件。

下面就主要看看 $\boldsymbol{Q}_t$ 的选择和最终分布 $q(\boldsymbol{x}_t|\boldsymbol{x}_0)$ （当 $T$ 趋于无穷，所谓的 stationary distributions） 。

### Markov transition matrices 的选择

D3PMs 的好处是，我们可以控制 $\boldsymbol{Q}_t$，其除了每一行加起来为 1 之外，唯一的约束就是，累乘之后的结果 $\overline{\boldsymbol{Q}}_{t}=\boldsymbol{Q}_{1}\boldsymbol{Q}_{2}\ldots\boldsymbol{Q}_{t}$ 必须收敛到一个已知的分布（当 $t$ 很大时）。

作者认为，大部分的离散数据，都可以在 $\boldsymbol{Q}_t$ 加上 domain-dependent structure 用于控制 forward corruption 过程，下面讨论三种矩阵。

Uniform：其实就是 Multinomial Diffusion 里面提出的：
$$\begin{aligned}\boldsymbol{Q}_t&=(1-\beta_t)\boldsymbol{I}+\beta_t/K\mathbb{1}\mathbb{1}^T,\quad \beta_t\in[0,1]\end{aligned}$$
最终的 stationary distribution 也是 uniform 的。

Absorbing state：考虑带有 absorbing state（称为 $[MASK]$）的传输矩阵，也就是每个 token 要么保持不变，要么以概率 $\beta_t$ 转移到 $[MASK]$ 这个 token。最终的 stationary distribution 不是 uniform 但是 has all the mass on the $[MASK]$ token。

Discretized Gaussian：模仿连续空间下的 diffusion，采用 离散的、截断的高斯分布。这样会使得相似状态之间的转移概率更高，非常适合图像这种 ordinal data。

Token embedding distance：文本数据没有 ordinal structure，但是也存在一些语义相关性。采用 embedding 空间中的相似度引导 forward 过程，构造  doubly-stochastic transition matrix，使得相似的 embedding 之间的转移概率更高，同时保证 stationary distribution 也是 uniform 的。

### Noise schedules

对于 discretized Gaussian diffusion，在离散化之前线性增加高斯分布的方差。

对于 uniform diffusion ，使用 cosine schedule，从而 cumulative probability  为 cosine 函数。

对于一个通用的 $\boldsymbol{Q}_t$，考虑从 $\boldsymbol{x}_t$ 到 $\boldsymbol{x}_0$ 到 $0$ 之间的互信息的插值，即 $I(\boldsymbol{x}_t;\boldsymbol{x}_0)\approx(1-\frac tT)H(\boldsymbol{x}_0)$。对于 absorbing-state D3PM，退化为 $(T-t+1)^{-1}$，此时正好是原始 DDPM 论文中提出的 Bernoulli diffusion process。

### 反向过程的参数化

虽然可以用神经网络直接预测反向过程 $p_\theta(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t)$，但是还是采用原始 DDPM 中的想法，也就是用神经网络 $\operatorname{nn}_\theta(\boldsymbol{x}_t)$ 预测 $\widetilde{p}_\theta(\widetilde{\boldsymbol{x}}_0|\boldsymbol{x}_t)$，从而参数化为：
$$p_\theta(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t)\propto\sum_{\widetilde{\boldsymbol{x}}_0}q(\boldsymbol{x}_{t-1},\boldsymbol{x}_t|\widetilde{\boldsymbol{x}}_0)\widetilde{p}_\theta(\widetilde{\boldsymbol{x}}_0|\boldsymbol{x}_t)$$

如果 $\widetilde{p}_\theta(\widetilde{\boldsymbol{x}}_0|\boldsymbol{x}_t)$ 只在 $\boldsymbol{x}_0$ 处有值（其他位置为 0）时，KL 散度 $D_\text{KL}[q(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,\boldsymbol{x}_0)||p_\theta(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t)]$ 为 0 。

### 损失函数

原始的 diffusion 优化负的变分下界 $L_{\mathrm{vb}}$，这里还引入了一个额外的去噪目标函数用于 $\boldsymbol{x}_0$ 的参数化，总的损失函数为：
$$L_\lambda=L_\mathrm{vb}+\lambda\operatorname{E}_{q(\boldsymbol{x}_0)}\mathbb{E}_{q(\boldsymbol{x}_t|\boldsymbol{x}_0)}[-\log\widetilde{p}_\theta(\boldsymbol{x}_0|\boldsymbol{x}_t)]$$
> 这里的第二项是不是可以看成是 VAE 中的重构损失。

### 和现有的文本概率模型的联系

D3PMs 其实和现有的文本概率语言模型存在一些联系。

BERT 其实是一个 one-step 的 diffusion：此时对应的 transition matrix 是 uniform transition matrix 和 absorbing state（$[MASK]$）的组合（即 $\boldsymbol{Q}=\alpha\mathbb{1}e_m^T+\beta\mathbb{1}\mathbb{1}^T/K+(1-\alpha-\beta)I$，其中 $e_m$ 是只在 $[MASK]$ 位置为 1 的 one-hot token。然后进行一步的 diffusion 过程，也就是这一步 $q(\boldsymbol{x}_1|\boldsymbol{x}_0)$ 会以 $10\%$ 的概率替换成 $[MASK]$，以 $5\%$ 的概率均匀采样为其他的 token，这其实就是 BERT 的目标函数：
$$L_{vb}-L_{T}=-\mathbb{E}_{q(\boldsymbol{x}_{1}|\boldsymbol{x}_{0})}[\operatorname{log}p_{\theta}(\boldsymbol{x}_{0}|\boldsymbol{x}_{1})]=L_{BERT}$$

自回归模型也是离散 diffusion 模型：考虑这样一种情况，$[MASK]$ token 是一个一个添加的，此时的 diffusion 的 time step 就是序列的长度 $N=T$，且 forward 过程可以写为：
$$q([\boldsymbol{x}_t]_i\mid{\boldsymbol{x}_0})=[\boldsymbol{x}_0]_i\mathrm{~if~}i<N-t \mathrm{~else~} [MASK]$$
此时 $q(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,\boldsymbol{x}_0)$ 为 delta 函数 $q(\left[\boldsymbol{x}_{t-1}\right]_i\left|\boldsymbol{x}_t,\boldsymbol{x}_0\right)={\delta}_{[\boldsymbol{x}_t]_i}\mathrm{~if~}i\neq T-t\mathrm{~else~}\delta_{[\boldsymbol{x}_0]_i}$。

此时的 KL 散度退化为 $D_{KL}(q([\boldsymbol{x}_{t-1}]_i|\boldsymbol{x}_t,\boldsymbol{x}_0)~||~p_\theta([\boldsymbol{x}_{t-1}]_i|\boldsymbol{x}_t))=-\log p_\theta([\boldsymbol{x}_0]_i|\boldsymbol{x}_t)$，其实就是自回归模型标准的交叉熵损失函数。

(Generative) Masked Language-Models (MLMs) 也是 diffusion 模型：MLM 通常是采样 $\boldsymbol{x}_0$ 然后，然后 mask $k$ 个 token，然后学习预测被 mask 的 token。可以证明， D3PM absorbing model trained on the usual ELBO objective with the x0-parameterization from 3.3 reduces to a reweighted version of this MLM objective。

# Vector Quantized Diffusion Model for Text-to-Image Synthesis
> CVPR 2022，中科大、微软

1. 提出 VQ-Diffusion，基于 VQ-VAE，但是 latent space 是用 diffusion model 建模的
2. 发现在 text-to-image 上的效果特别好，而且生成效率也很高

## Introduction

1. 自回归模型如 DALL-E 可以实现非常好的 text-to-image 生成
2. 但是会存在一些问题：
	1. unidirectional bias，现有的方式都是以 reading order 来预测 pixel 或 token，这种固定的顺序就会引入 bias，因为上下文信息不仅仅来自于之前的 token
	2. 预测误差累计，推理时每个 step 都是基于前一个 token 的，但是训练时却不是这样的（也就是所谓的 teacher-forcing ），从而可能导致误差传播
3. 提出 VQ-Diffusion，采用 DDPM 的变体来建模 latent space，forward 过程逐渐在 latent variables 上加噪
4. VQ-Diffusion 可以减轻 unidirectional bias，其包含一个 独立的 text encoder 和一个 diffusion image decoder，推理时，所有的 image token 要么 mask 要么随机，然后 diffusion model 根据输入文本逐步估计 image token 的分布，每个 step 都可以看到所有的上下文信息
5. 同时由于采用了 mask-and-replace 的 diffusion 策略，也可以避免误差累计，因为训练的时候没用 teacher forcing，而是 mask token 或者 random token，推理的时候每个 step 会重新采样所有的 token，从而可以修正错误的 token 来避免误差的累积

## 相关工作（略）

## 背景：使用 VQ-VAE 学习 discrete latent space

VQ-VAE 包含 encoder $E$，decoder $G$ 和 codebook $\mathcal{Z}=\{z_k\}_{k=1}^K\in\mathbb{R}^{K\times d}$，$K$ 为向量的数量，$d$ 为编码的维度。给定图像 $\boldsymbol{x}\in\mathbb{R}H\times W\times3$，使用 encoder 得到一些列 image token $\boldsymbol{z}_q$，即首先 $\boldsymbol{z}=E(\boldsymbol{x})\in\mathbb{R}^{h\times w\times d}$，然后使用量化器 $Q(\cdot)$ 进行量化，也就是将每个 $\boldsymbol{z}_{i,j}$ 映射到最 codebook 中最邻近的编码 $\boldsymbol{z}_k$，从而：
$$\boldsymbol{z}_q=Q(\boldsymbol{z})=\left(\operatorname*{argmin}_{\boldsymbol{z}_k\in\mathcal{Z}}\|\boldsymbol{z}_{ij}-\boldsymbol{z}_k\|_2^2\right)\in\mathbb{R}^{h\times w\times d}$$
其中 $h\times w$ 为 encoder 之后的长度。然后通过 decoder 重构图像 $\tilde{\boldsymbol{x}}=G\left(\boldsymbol{z}_q\right)$。此时，图像生成就变成，从 latent distribution 中采样 image token。encoder $E$，decoder $G$ 和 codebook $\mathcal{Z}$ 可以通过一下损失端到端地训练：
$$\begin{array}{r}
\mathcal{L}_{\mathrm{VQVAE}}=\|\boldsymbol{x}-\tilde{\boldsymbol{x}}\|_1+\left\|\operatorname{sg}[E(\boldsymbol{x})]-z_q\right\|_2^2 \\
+\beta\left\|\operatorname{sg}\left[z_q\right]-E(\boldsymbol{x})\right\|_2^2
\end{array}$$
其中的 $\operatorname{sg}$ 为  stop-gradient。将上式中的第二项替换为 exponential moving averages (EMA) 来更新 codebook。

## VQ-Diffusion

给定文本图像对，采用预训练的 VQ-VAE 来得到离散的 image token $\boldsymbol{x} \in \mathbb{Z}^N$，其中 $N=h\times w$ 表示序列长度。位置 $i$ 的 token $x^i$ 对应 codebook 中的 index，即 $x^i \in\{1,2, \ldots, K\}$，同时 text token $\boldsymbol{y} \in \mathbb{Z}^M$ 通过 BPE-encoding 获得。此时 text-to-image 可以被看作是最大化条件分布 $q(\boldsymbol{x} \mid \boldsymbol{y})$。

自回归模型是这么建模的：
$$q(\boldsymbol{x} \mid \boldsymbol{y})=\prod_{i=1}^N q\left(x^i \mid x^1, \cdots, x^{i-1}, \boldsymbol{y}\right)$$
由于 token 是一个一个预测的，忽略了数据的 2D 结构。

提出的 VQ-Diffusion 则采用 diffusion 来最大化这个分布。

### Discrete diffusion process

forward diffusion 通过马尔可夫链 $q\left(\boldsymbol{x}_t \mid \boldsymbol{x}_{t-1}\right)$ 逐渐引入噪声，即随机替换 $\boldsymbol{x}_{t-1}$ 中的部分 token，从而得到一系列的带有噪声的 latent variables，$\boldsymbol{z}_1, \ldots, \boldsymbol{z}_T$，其中 $\boldsymbol{z}_T$ 为纯噪声。

reverse diffusion 从 $\boldsymbol{z}_T$ 开始，从 latent variables 中逐步降噪，通过从 $q\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, \boldsymbol{x}_0\right)$ 中进行采样来恢复数据。但是由于推理时 $\boldsymbol{x}_0$ 是未知的，于是训练一个 transformer  网络来近似 $p_\theta\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, \boldsymbol{y}\right)$。

给定 image token 记为 $x_0^i \in\{1,2, \ldots, K\}$，忽略上标的位置，简写为 $x_0$。

定义转移概率 $\left[\boldsymbol{Q}_t\right]_{m n}=q\left(x_t=m \mid x_{t-1}=n\right) \in\mathbb{R}^{K\times K}$  ，此时 forward Markov diffusion 可以写为：
$$q\left(x_t \mid x_{t-1}\right)=\boldsymbol{v}^{\top}\left(x_t\right) \boldsymbol{Q}_t \boldsymbol{v}\left(x_{t-1}\right)$$
> 分析可知，$q\left(x_t \mid x_{t-1}\right)$ 其实是一个矩阵，第 $m,n$ 的位置表示 转换概率 $\left[\boldsymbol{Q}_t\right]_{m n}$。

其中 $\boldsymbol{v}(x)$ 是长为 $K$ 的 one-hot 向量（只在位置 $x$ 为 1）。同时根据马尔可夫链的性质，有：
$$q\left(x_t \mid x_0\right)=\boldsymbol{v}^{\top}\left(x_t\right) \overline{\boldsymbol{Q}}_t \boldsymbol{v}\left(x_0\right), \text { with } \overline{\boldsymbol{Q}}_t=\boldsymbol{Q}_t \cdots \boldsymbol{Q}_1$$
还有：
$$\begin{aligned}
q(x_{t-1}|x_t,x_0)=\frac{q(x_t|x_{t-1},x_0)q(x_{t-1}|x_0)}{q(x_t|x_0)} \\
\begin{aligned}=\frac{\left(\boldsymbol{v}^\top(x_t)\boldsymbol{Q}_t\boldsymbol{v}(x_{t-1})\right)\left(\boldsymbol{v}^\top(x_{t-1})\overline{\boldsymbol{Q}}_{t-1}\boldsymbol{v}(x_0)\right)}{\boldsymbol{v}^\top(x_t)\overline{\boldsymbol{Q}}_t\boldsymbol{v}(x_0)}.\end{aligned}
\end{aligned}$$
之前的工作提出，在 categorical distribution 中引入一个小的均匀分布的噪声，此时转移矩阵 $\boldsymbol{Q}_t$ 定义为：
$$\boldsymbol{Q}_t=\left[\begin{array}{cccc}
\alpha_t+\beta_t & \beta_t & \cdots & \beta_t \\
\beta_t & \alpha_t+\beta_t & \cdots & \beta_t \\
\vdots & \vdots & \ddots & \vdots \\
\beta_t & \beta_t & \cdots & \alpha_t+\beta_t
\end{array}\right]$$
其中，$\alpha_t \in[0,1] , \beta_t=\left(1-\alpha_t\right) / K$，这说明每个 token 都有 $(\alpha_t+\beta_{t)}$ 的概率保持不变，有 $K\beta_t$ 的概率从 $K$ 个 token 中均匀采样。

但是，采用均匀分布进行加噪可能有一些问题，因为 token 是有语义信息的，从一个 token 转移到另一个 token 并不可能的完全等概的。
> 这相当于是给了模型一个错误的先验，导致学习的时候会存在某种冲突？

于是提出 Mask-and-replace diffusion strategy，随机 mask 一部分 token，引入一个额外的 token，称为 $[MASK]$，此时就有 $K+1$ 个转移状态。定义 mask diffusion 如下：每个普通的 token（$K$个）都有概率 $\gamma_t$ 被替换为 $[MASK]$，有概率 $K\beta_t$ 均匀采样，有概率 $\alpha_t=1-K\beta_t-\gamma_t$ 保持不变，而如果一个 token 是 $[MASK]$ 则永远保持不变。此时的转移矩阵定义为：
$$\boldsymbol{Q}_t=\begin{bmatrix}\alpha_t+\beta_t&\beta_t&\beta_t&\cdots&0\\\beta_t&\alpha_t+\beta_t&\beta_t&\cdots&0\\\beta_t&\beta_t&\alpha_t+\beta_t&\cdots&0\\\vdots&\vdots&\vdots&\ddots&\vdots\\\gamma_t&\gamma_t&\gamma_t&\cdots&1\end{bmatrix}$$
这种策略的好处是：
+ 改变后的 token 更容易被网络区分，从而使得 reverse 过程更简单
+ 相比于仅做 mask，需要一个均匀噪声，否则会有问题
+ 替换操作使得模型需要理解上下文而非仅关注于 mask token
+ cumulative 转移矩阵可以计算了：$\overline{\boldsymbol{Q}}_t\boldsymbol{v}(x_0)=\overline{\alpha}_t\boldsymbol{v}(x_0)+(\overline{\gamma}_t-\overline{\beta}_t)\boldsymbol{v}(K+1)+\overline{\beta}_t$
+ 计算复杂度也降低了

### reverse 过程

训练一个 denoising 网络 $p_\theta(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,\boldsymbol{y})$，通过最小化变分下界来训练：
$$\begin{aligned}
\mathcal{L}_{vlb}& =\mathcal{L}_0+\mathcal{L}_1+\cdots+\mathcal{L}_{T-1}+\mathcal{L}_T,  \\
\mathcal{L}_0& =-\log p_\theta(\boldsymbol{x}_0|\boldsymbol{x}_1,\boldsymbol{y}),  \\
\mathcal{L}_{t-1}& =D_{KL}(q(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,\boldsymbol{x}_0)\mid\mid p_\theta(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,\boldsymbol{y})),  \\
\mathcal{L}_T& =D_{KL}(q(\boldsymbol{x}_T|\boldsymbol{x}_0)\mid\mid p(\boldsymbol{x}_T)). 
\end{aligned}$$
其中 $p(\boldsymbol{x}_T)$ 为先验分布，在 mask-and-replace 策略下，为：
$$p(\boldsymbol{x}_T)=\begin{bmatrix}\overline{\beta}_T,\overline{\beta}_T,\cdots,\overline{\beta}_T,\overline{\gamma}_T\end{bmatrix}^\top $$
> $p(\boldsymbol{x}_T)$ 就是纯噪声分布，$K$ 个正常的 token 之间是均匀分布。

网络是如何参数化的很大程度会影响合成质量，除了直接预测后验 $q\left(\boldsymbol{x}_{t-1} \mid \boldsymbol{x}_t, \boldsymbol{x}_0\right)$ ，直接让网络预测原始的无噪声的 target 分布 $q(\boldsymbol{x}_0)$ 会有更好的质量。
> 不就是 DDPM 的意思。。。不是预测下一个 time step 而是直接预测无噪的样本。

这里作者预测的是 $p_\theta(\tilde{\boldsymbol{x}}_0|\boldsymbol{x}_t,\boldsymbol{y})$，从而可以计算 reverse transition distribution 为：
$$p_\theta(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,\boldsymbol{y})=\sum_{\tilde{\boldsymbol{x}}_0=1}^Kq(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,\tilde{\boldsymbol{x}}_0)p_\theta(\tilde{\boldsymbol{x}}_0|\boldsymbol{x}_t,\boldsymbol{y})$$
然后引入一个辅助的 denoising  目标函数，使模型可以预测 $\boldsymbol{x}_0$：
$$\mathcal{L}_{x_0}=-\log p_\theta(\boldsymbol{x}_0|\boldsymbol{x}_t,\boldsymbol{y})$$

提出用 encoder-decoder transformer 来估计分布 $p_\theta(\tilde{\boldsymbol{x}}_0|\boldsymbol{x}_t,\boldsymbol{y})$，架构如图：
![](image/Pasted%20image%2020231003232547.png)
diffusion image decoder 的输入为 当前的 image token $\boldsymbol{x}_t$、time step $t$ ，然后得到分布 $p_\theta(\tilde{\boldsymbol{x}}_0|\boldsymbol{x}_t,\boldsymbol{y})$，$t$ 是通过 Adaptive Layer Normalization 操作引入的，即：
$$\operatorname{AdaLN}(h,t)=a_t\text{LayerNorm}(h)+b_t$$

推理时，可以跳过一些步骤来实现快速的推理。假设 time stride 是 $\Delta_t$，实际上可以不需要按照 $x_T,x_{T-1},x_{T-2},\dots,x_0$，而可以按照 $x_T,x_{T-\Delta_t},x_{T-2\Delta_t}\dots x_0$ 来采样：
$$p_\theta(x_{t-\Delta_t}|x_t,y)=\sum_{\tilde{x}_0=1}^Kq(x_{t-\Delta_t}|x_t,\tilde{x}_0)p_\theta(\tilde{x}_0|x_t,y)$$
> 其实就是 DDIM 中的方法。

## 实验（略）

# UniCATS- A Unified Context-Aware Text-to-Speech Framework with Contextual VQ-Diffusion and Vocoding

> preprint，上海交大、思必驰，俞凯

1. 离散 speech  token 可以分为 语义 token 和 声学 token
2.  VALL-E 和 SPEAR-TTS 可以通过自回归的连续声学 token 实现 zero-shot speaker adaptation
3. 但是 AR 模型是有序的预测，不适用于 speech editing 这种可以看到之前和之后上下文的任务
4. 本文提出一种 unified context-aware TTS 框架，称为 UniCATS，可以实现 speech continuation 和 editing，包含两个部分：
	1. 声学模型 CTX-txt2vec，采用 contextual VQ-diffusion 从文本预测语义 token
	2. vocoder CTX-vec2wav，采用 contextual vocoding 将语义 token 转为 波形
5. 在 speech continuation and editing 上实现了 SOTA

## Introduction

1. speech continuation 和 editing 任务描述

![](image/Pasted%20image%2020231013154129.png)

2. 当前基于 discrete speech tokens 的 TTS 方法有三个限制：
	1. 大部分都是自回归模型，从而只能是  left-to-right 方向，不适用于 speech editing
	2. 声学 token 的构建涉及 RVQ，需要多次索引
	3. 音频质量受限于 audio codec 模型
3. 提出 UniCATS

![](image/Pasted%20image%2020231013154633.png)

其中：
+ CTX-txt2vec 采用 contextual VQ-diffusion 从输入文本中预测语义 token
+ vocoder CTX-vec2wav 用 contextual vocoding 将语义 token 转为 波形，同时也会考虑 acoustic context（尤其是 speaker  identity）

## UniCATS

### CTX-txt2vec with Contextual VQ-diffusion

采用 vq-wav2vec token 作为语义 token。

考虑离散样本序列 $\boldsymbol{x}_0=[x_0^{(1)},x_0^{(2)},...,x_0^{(l)}]\mathrm{~where~}x_0^{(i)}\in\{1,2,...,K\}$，在每个 forward step 中吗，对 $\boldsymbol{x}_0$ 的每个样本执行 mask、替换 或保持不变 三种操作，最终得到的样本记为 $\boldsymbol{x}_t$，此时 forward 过程为：
$$q(x_t|x_{t-1})=\boldsymbol{v}^\top(x_t)\boldsymbol{Q}_t\boldsymbol{v}(x_{t-1})$$
其中 $\boldsymbol{v}(x_t)\in\mathbb{R}^{(K+1)}$ 表示 $x_t=k$ 的位置 为 1（其他位置为 0）的 one-hot 向量。$K+1$ 的 $1$ 表示 $[mask]$ token，$\boldsymbol{Q}_t\in\mathbb{R}^{(K+1)\times(K+1)}$ 为传输矩阵。多个 forward 过程得到：
$$q(x_t|x_0)=\boldsymbol{v}^\top(x_t)\overline{\boldsymbol{Q}}_t\boldsymbol{\upsilon}(x_0)$$
采用贝叶斯规则也可以计算：
$$\begin{aligned}
\begin{aligned}q(x_{t-1}|x_t,x_0)=\frac{q(x_t|x_{t-1},x_0)q(x_{t-1}|x_0)}{q(x_t|x_0)}\end{aligned} \\
=\frac{\left(\boldsymbol{v}^\top(x_t)\boldsymbol{Q}_t\boldsymbol{v}(x_{t-1})\right)\left(\boldsymbol{v}^\top(x_{t-1})\overline{\boldsymbol{Q}}_{t-1}\boldsymbol{v}(x_0)\right)}{\boldsymbol{v}^\top(x_t)\overline{\boldsymbol{Q}}_t\boldsymbol{v}(x_0)}.
\end{aligned}$$
 采用堆叠的 Transformer blocks  来构建 VQ-diffusion，模型用于估计分布 $p_\theta(\tilde{\boldsymbol{x}}_0|\boldsymbol{x}_t,\boldsymbol{y})$，推理的时候采样过程如下：
 $$p_\theta(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,\boldsymbol{y})=\sum_{\tilde{\boldsymbol{x}}_0}q(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,\tilde{\boldsymbol{x}}_0)p_\theta(\widetilde{\boldsymbol{x}}_0|\boldsymbol{x}_t,\boldsymbol{y}).$$
这里的 $\boldsymbol{y}$ 为输入的文本。

由于任务是 speech editing and continuation，还需要考虑额外的 context token $\boldsymbol{c}^A,\boldsymbol{c}^B$，也就是要建模概率：
$$p_\theta(\tilde{\boldsymbol{x}}_0|\boldsymbol{x}_t,\boldsymbol{y},\boldsymbol{c}^A,\boldsymbol{c}^B)$$
于是提出以时间顺序将 $\boldsymbol{x}_t$ 和 $\boldsymbol{c}^A,\boldsymbol{c}^B$ 进行拼接，得到 $[\boldsymbol{c}^A,\boldsymbol{x}_t,\boldsymbol{c}^B]$ ，然后再送入到 VQ-diffusion 模型中，此时后验分布计算为：
$$\begin{aligned}
&p_\theta(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,\boldsymbol{y},\boldsymbol{c}^A,\boldsymbol{c}^B) \\
&=\sum_{\widetilde{\boldsymbol{x}}_0}q(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,\widetilde{\boldsymbol{x}}_0)p_\theta(\widetilde{\boldsymbol{x}}_0|\boldsymbol{x}_t,\boldsymbol{y},\boldsymbol{c}^A,\boldsymbol{c}^B).
\end{aligned}$$
> 这里的 $\boldsymbol{c}^A,\boldsymbol{c}^B$ 其实就是前面、后面的语音。

其模型架构如下：
![](image/Pasted%20image%2020231013202848.png)
采用了一个长度和输入相同的 binary indicator sequence 来区分数据和 context。

VQ- diffusion 的结构和 [Vector Quantized Diffusion Model for Text-to-Image Synthesis 笔记](../图像合成系列论文阅读笔记/Vector%20Quantized%20Diffusion%20Model%20for%20Text-to-Image%20Synthesis%20笔记.md) 一样，但是没有使用 cross attention，而是直接把 $\boldsymbol{h}$ 加入到 self-attention layers 的输出，从而实现 $\boldsymbol{h}$ 和语义 token 之间严格的对齐。最后通过 softmax 来得到 $p_\theta(\tilde{\boldsymbol{x}}_0|\boldsymbol{x}_t,\boldsymbol{y},\boldsymbol{c}^A,\boldsymbol{c}^B)$ 的分布。

损失函数为：
$$\mathcal{L}_{\text{CTX-txt}2\text{vec}} = \mathcal{L}_{\text{duration}} + \gamma \mathcal{L}_{\text{VQ-diffusion}}$$


推理流程如下：
![](image/Pasted%20image%2020231013210003.png)

### CTX-vec2wav with Contextual Vocoding

模型架构如图：
![](image/Pasted%20image%2020231013210145.png)

首先将语义 token 通过两层 semantic encoders，然后通过 generator（卷积+上采样）得到波形。中间还有一个辅助的 feature adaptor，其功能类似于 FastSpeech 2 中的 variance adaptor。训练的时候，还使用了 ground-truth auxiliary features 作为条件，模型学习从第一个 encoder 的输出来预测这些条件。推理的时候，把这些辅助特征作为条件。

语义 token 主要捕获发音信息但是缺乏足够的声学细节，尤其是 speaker identify，于是提出采用  mel 谱 $m$ 来 prompt 声学 context。从而 semantic encoder 中的 cross attention 可以将来自 mel 谱 中的 声学 context 进行集成，从而可以提高 speaker similarity。
> 简单来说就是通过 mel 谱 来引入一些说话人的信息。

### Unified framework for context-aware TTS

speech continuation and editing 和唯一区别在于 context $B$ 是否存在。前面的描述中去掉 $B$ 之后就可以实现 speech continuation。

## 实验和结果